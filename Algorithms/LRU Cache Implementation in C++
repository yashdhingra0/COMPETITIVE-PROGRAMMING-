 WHAT IS LRU CACHE ?
 We are given total possible page numbers that can be referred. We are also given cache (or memory) size (Number of page frames that cache can hold at a time). 
 The LRU caching scheme is to remove the least recently used frame when the cache is full and a new page is referenced which is not there in cache.
 
 We use two data structures to implement an LRU Cache. 
 QUEUE AS DOUBLY LINKED LIST
 AND HASH TO STORE THE ADDRESS O THE PAGE STORED IN A QUEUE
 
 COSTS                        Worst Case
space 	                        O(n)
get least recently used item 	O(1)
access item 	                O(1)
 
  WHY DLL USED NOT SIMPLE LINKED LIST??
  In general, finding an item in a linked list is O(n) time, since we need to walk the whole list.
  But the whole point of a cache is to get quick lookups. How could we speed that up?

We'll add in a hash map that maps items to linked list nodes: 
That lets us find an element in our cache's linked list in O(1)O(1)O(1) time, instead of O(n).


ALGORITHM

 Accessing and Evicting

Putting things together, here are the steps we'd run through each time an item was accessed:

    Look up the item in our hash map.

    If the item is in the hash table, then it's already in our cache—this is called a "cache hit"

        Use the hash table to quickly find the corresponding linked list node.

        Move the item's linked list node to the head of the linked list, since it's now the most recently used (so it shouldn't get evicted any time soon).

    If the item isn't in the hash table, we have a cache miss. We need to load the item into the cache:

        Is our cache full? If so, we need to evict something to make room:

            Grab the least-recently used cache item—it'll be at the tail of the linked list.

            Evict that item from the cache by removing it from the linked list and the hash map.

        Create a new linked list node for the item. Insert it at the head of the linked list.

        Add the item to our hash map, storing the newly-created linked list node as the value.


             ******************************************IMPLEMENTATION*************************************************************************************************

#include <bits/stdc++.h> 
using namespace std; 

class LRUCache { 
    
	deque<int> dq; 
	unordered_map<int, deque<int>::iterator> m;  //HERE IN MAP WE TAKE ITERATOR BECAUSE WE WANT TO STORE THE ADDRESS OF KEY WHERE IT IS STORED IN DEQUE 
	int size;

public: 
	LRUCache(int); 
	void insert(int); 
	void display(); 
}; 

LRUCache::LRUCache(int n) { size = n; } 


void LRUCache::insert(int x) 
{ // not present in HASH
	if (m.find(x) == m.end()) { //  CHECK THE NODE IS PRESENT IN HASH OR NOT(HERE NOT PRESENT ) 
		if (dq.size() == size) { //  IF CACHE IS FULL 
			int last = dq.back(); 
             dq.pop_back(); delete least recently used element
               m.erase(last); 
		} } 
// present in HASH
	else
		dq.erase(m[x]); //erase() function is used to remove elements from a container from the specified position or range IN 0(1).

	dq.push_front(x); //This function is used to push elements into a deque from the front.
	m[x] = dq.begin();// begin() function is used to return an iterator pointing to the first element of the deque container. 
} 

void LRUCache::display() 
{ 
	for (auto it = dq.begin(); it != dq.end(); it++) 
		cout << (*it) << " "; 
         cout << endl; 
} 
int main() 
{ 
	LRUCache ca(4); 

	ca.insert(1); 
	ca.insert(2); 
	ca.insert(3); 
	ca.insert(1); 
	ca.insert(4); 
	ca.insert(5); 
	ca.display(); 

	return 0; 
} 
//output
//5 4 1 3 


                  | map             | unordered_map
---------------------------------------------------------
Ordering        | increasing  order   | no ordering
                | (by default)        |

Implementation  | Self balancing BST  | Hash Table
                | like Red-Black Tree |  

search time     | log(n)              | O(1) -> Average 
                |                     | O(n) -> Worst Case

Insertion time  | log(n) + Rebalance  | Same as search
                      
Deletion time   | log(n) + Rebalance  | Same as search
